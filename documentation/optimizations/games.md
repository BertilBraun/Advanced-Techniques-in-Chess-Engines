# Game Specific Optimizations

## Symmetric Variations

Most games have symmetric variations, which can be used to reduce the number of states that have to be evaluated and yield more training samples or reducing the chance of overfitting, as a game line will not always be added in the same orientation. This is especially useful for games with a high correlation between successive board states, such as Connect4, Hex or Go. The model recognizes the board line and overfits the value head to the board line, which is not desirable. Therefore, we use symmetries to permute the input board states and not add all variations of the same board state, but only a few of them. This way, the model is trained on a more diverse dataset and the training is more stable. These symmetries have to ensure, that the orientation is still preserved, i.e. in chess, each encoded board must have the current player on top.

TicTacToe can use 4 rotational symmetries and 2 mirror symmetries, which gives a total of 8 symmetries. This can be used to reduce the number of states that have to be evaluated and yield more training samples.
Connect4 can use a vertical mirror symmetry, all other symmetries are not valid, as they would change the orientation of the board.
Chess does not have any real symmetries, as the orientation of the board is important. However, the board can be mirrored as an approximation, which up to very high levels of play is not distinguishable from the original board. This can be used to reduce the number of states that have to be evaluated and yield more training samples.

## Chess Encoding

The input representation for the chess engine is a multi-layered structure. It consists of 12 bit-boards for each piece type (six for white and six for black), four planes for castling rights, two for piece occupancy (one for all white pieces, one for all black), a single plane to indicate checkers, and six scalar planes representing the material difference. To simplify the learning process for the neural network, the board is always oriented from the perspective of the white player. This means that whenever it's black's turn to move, the board state is flipped before being fed into the network, so it doesn't have to learn the game from two different perspectives.

The policy head of the network maps the board state to an optimized 1814-dimensional policy vector. This vector is specifically designed to be efficient by excluding moves that are impossible under the rules of chess, such as a piece moving from A1 to H6 in a single turn. Furthermore, because the board is always presented from white's point of view, all potential promotion and castling moves for black are removed from this policy vector, further streamlining the output.

To handle games that might otherwise continue indefinitely, specific termination rules are implemented. Games are automatically declared as draws if they exceed 200 moves or if they continue for an extended period with very few pieces left on the board. In these scenarios, instead of assigning a simple draw score of 0.0, a more nuanced evaluation is used. A weighted count of the remaining pieces provides an approximate result score, offering a better training target for the value head. This score is scaled to a range of -0.5 to 0.5 for excessively long games, and to a range of -1.0 to 1.0 for games with few pieces, as the latter situation is more likely to have a clear winner in the near future.
