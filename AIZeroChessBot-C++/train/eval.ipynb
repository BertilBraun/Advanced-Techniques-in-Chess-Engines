{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook for the AIZero Chess Bot\n",
    "\n",
    "- Bot prediction from Fen string\n",
    "- Bot plays against itself\n",
    "- Bot vs Human\n",
    "- Bot vs Baseline Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal, Optional\n",
    "from chess import Board, Move, WHITE, BLACK, Color\n",
    "\n",
    "\n",
    "TIME_TO_THINK = 0.5  # seconds\n",
    "\n",
    "\n",
    "class ChessBot(ABC):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        \"\"\"Initializes the bot with a name.\"\"\"\n",
    "        self.name = name\n",
    "        self.start_time = 0.0\n",
    "\n",
    "    @abstractmethod\n",
    "    def think(self, board: Board) -> Move:\n",
    "        \"\"\"This method is called when it's the bot's turn to move. It should return the move that the bot wants to make.\"\"\"\n",
    "        raise NotImplementedError('Subclasses must implement this method')\n",
    "\n",
    "    @property\n",
    "    def time_elapsed(self) -> float:\n",
    "        \"\"\"Returns the time elapsed since the bot started thinking.\"\"\"\n",
    "        return time.time() - self.start_time\n",
    "\n",
    "    @property\n",
    "    def time_remaining(self) -> float:\n",
    "        \"\"\"\n",
    "        Determines the time remaining for the bot to think.\n",
    "\n",
    "        :return: The time remaining in seconds.\n",
    "        \"\"\"\n",
    "        return TIME_TO_THINK - self.time_elapsed\n",
    "\n",
    "    @property\n",
    "    def time_is_up(self) -> bool:\n",
    "        \"\"\"Determines if the bot has run out of time to think.\"\"\"\n",
    "        return self.time_remaining <= 0\n",
    "\n",
    "    def restart_clock(self) -> None:\n",
    "        \"\"\"Restarts the clock for the bot.\"\"\"\n",
    "        self.start_time = time.time()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GameResult:\n",
    "    winner: Optional[Color]\n",
    "    result: Literal['1-0', '0-1', '1/2-1/2', 'unfinished']\n",
    "\n",
    "    @staticmethod\n",
    "    def from_board(board: Board) -> 'GameResult':\n",
    "        if board.is_checkmate():\n",
    "            result = '1-0' if board.turn == BLACK else '0-1'\n",
    "            return GameResult(board.turn, result)\n",
    "\n",
    "        if board.is_game_over():\n",
    "            return GameResult(None, '1/2-1/2')\n",
    "\n",
    "        return GameResult(None, 'unfinished')\n",
    "\n",
    "\n",
    "class GameManager:\n",
    "    def __init__(self, white: ChessBot, black: ChessBot) -> None:\n",
    "        \"\"\"Initializes the game manager with two players.\"\"\"\n",
    "        self.white = white\n",
    "        self.black = black\n",
    "\n",
    "    def play_game(self, verify_moves=True) -> GameResult:\n",
    "        \"\"\"Manages the gameplay loop until the game is over or a player quits.\"\"\"\n",
    "        board = Board()\n",
    "        \n",
    "        while not board.is_game_over():\n",
    "            current_player = self.white if board.turn == WHITE else self.black\n",
    "\n",
    "            current_player.restart_clock()\n",
    "            move = current_player.think(board)\n",
    "\n",
    "            if verify_moves and move not in board.legal_moves:\n",
    "                raise ValueError(f'Invalid move {move} for player {current_player.name}')\n",
    "\n",
    "            board.push(move)\n",
    "\n",
    "        return GameResult.from_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess import Board, Move\n",
    "import chess.svg\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "class HumanPlayer(ChessBot):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initializes the human player.\"\"\"\n",
    "        super().__init__('Human')\n",
    "\n",
    "    def think(self, board: Board) -> Move:\n",
    "        \"\"\"Allows a human player to input a move using the GUI.\"\"\"\n",
    "        boardsvg = chess.svg.board(board, size=350)\n",
    "        clear_output(wait=True)\n",
    "        display(boardsvg)\n",
    "        \n",
    "        print('Legal moves:', [move.uci() for move in board.legal_moves])\n",
    "        while True:\n",
    "            move = input('Enter your move: ')\n",
    "            try:\n",
    "                move = Move.from_uci(move)\n",
    "                if move in board.legal_moves:\n",
    "                    return move\n",
    "                print('Invalid move. Try again.')\n",
    "            except ValueError:\n",
    "                print('Invalid move. Try again.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "from torch import nn, Tensor, softmax\n",
    "\n",
    "\n",
    "ROW_COUNT = 8\n",
    "COLUMN_COUNT = 8\n",
    "NUM_RES_BLOCKS = 8\n",
    "NUM_HIDDEN = 256\n",
    "\n",
    "ENCODING_CHANNELS = 6 + 6  # 6 channels for the pieces of the current player and 6 channels for the pieces of the opponent\n",
    "ACTION_SIZE = 1968\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"\n",
    "    The neural network model for the AlphaZero bot.\n",
    "\n",
    "    The architecture is based on the AlphaZero paper, but with less layers.\n",
    "\n",
    "    We use a residual neural network with 8 residual blocks.\n",
    "    The input to the network is a 12x8x8 tensor representing the board state with 6 channels for the pieces of the current player and 6 channels for the pieces of the opponent.\n",
    "    The output of the network is a policy over all possible moves and a value for the current board state.\n",
    "\n",
    "    The amount of parameters in the network is ~13.5 million (13.591.258).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Conv2d(ENCODING_CHANNELS, NUM_HIDDEN, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(NUM_HIDDEN),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.backBone = nn.ModuleList([ResBlock(NUM_HIDDEN) for _ in range(NUM_RES_BLOCKS)])\n",
    "\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(NUM_HIDDEN, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * ROW_COUNT * COLUMN_COUNT, ACTION_SIZE),\n",
    "        )\n",
    "\n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(NUM_HIDDEN, 3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * ROW_COUNT * COLUMN_COUNT, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "\n",
    "    def inference(self, x: Tensor) -> tuple[NDArray[np.float32], NDArray[np.float32]]:\n",
    "        result: tuple[Tensor, Tensor] = self(x)\n",
    "        policy, value = result\n",
    "        policy = softmax(policy, dim=1).cpu().numpy()\n",
    "        value = value.squeeze(1).cpu().numpy()\n",
    "        return policy, value\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_path() -> str:\n",
    "    with open('models/last_training_config.pt') as f:\n",
    "        items = {line.split('=')[0]: line.split('=')[1] for line in f.readlines()}\n",
    "        return items['model'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess import PIECE_TYPES, SQUARES, square_rank, square_file, WHITE, BLACK, QUEEN, ROOK, BISHOP, KNIGHT, PAWN, PieceType, Square, square\n",
    "\n",
    "def encode_board(board: Board) -> Tensor:\n",
    "    encodedBoard = torch.zeros((ENCODING_CHANNELS, ROW_COUNT, COLUMN_COUNT), dtype=torch.float32)\n",
    "\n",
    "    for color in [WHITE, BLACK]:\n",
    "        for piece in PIECE_TYPES:\n",
    "            layerIndex = color * 6 + piece - 1\n",
    "            bitboard = board.pieces_mask(piece, color)\n",
    "            \n",
    "            for square in SQUARES:\n",
    "                row = square_rank(square)\n",
    "                col = square_file(square)\n",
    "                if bitboard & (1 << square):\n",
    "                    encodedBoard[layerIndex][row][col] = 1\n",
    "                    \n",
    "    return encodedBoard\n",
    "\n",
    "def encode_boards(boards: list[Board]) -> Tensor:\n",
    "    return torch.stack([encode_board(board) for board in boards])\n",
    "\n",
    "\n",
    "def filter_policy_then_get_moves_and_probabilities(\n",
    "    policy: NDArray[np.float32], board: Board\n",
    ") -> list[tuple[Move, float]]:\n",
    "    \"\"\"\n",
    "    Gets a list of moves with their corresponding probabilities from a policy.\n",
    "\n",
    "    The policy is a 1D numpy array representing the probabilities of each move\n",
    "    in the board. The list of moves is a list of tuples, where each tuple contains\n",
    "    a move and its corresponding probability.\n",
    "\n",
    "    :param policy: The policy to get the moves and probabilities from.\n",
    "    :param board: The chess board to filter the policy with.\n",
    "    :return: The list of moves with their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    filtered_policy = __filter_policy_with_legal_moves(policy, board)\n",
    "    moves_with_probabilities = __map_policy_to_moves(filtered_policy)\n",
    "    return moves_with_probabilities\n",
    "\n",
    "\n",
    "def encode_move(move: Move) -> int:\n",
    "    \"\"\"\n",
    "    Encodes a chess move into a move index.\n",
    "\n",
    "    :param move: The move to encode.\n",
    "    :param current_player: The current player to encode the move for.\n",
    "    :return: The encoded move index.\n",
    "    \"\"\"\n",
    "    if move.promotion not in __MOVE_MAPPINGS[move.from_square][move.to_square]:\n",
    "        raise ValueError(f'Error: move.promotion not in MOVE_MAPPINGS[move.from_square][move.to_square]: {move}')\n",
    "\n",
    "    return __MOVE_MAPPINGS[move.from_square][move.to_square][move.promotion]\n",
    "\n",
    "\n",
    "def decode_move(move_index: int) -> Move:\n",
    "    \"\"\"\n",
    "    Decodes a move index into a chess move.\n",
    "\n",
    "    :param move_index: The index of the move to decode.\n",
    "    :return: The decoded chess move.\n",
    "    \"\"\"\n",
    "    from_square, to_square, promotion_type = __REVERSE_MOVE_MAPPINGS[move_index]\n",
    "    return Move(from_square, to_square, promotion=promotion_type)\n",
    "\n",
    "\n",
    "def decode_moves(move_indices: NDArray[np.int32]) -> list[Move]:\n",
    "    \"\"\"\n",
    "    Decodes an array of move indices into a list of chess moves.\n",
    "\n",
    "    :param move_indices: The array of move indices to decode.\n",
    "    :return: The list of decoded chess moves.\n",
    "    \"\"\"\n",
    "    moves = [__REVERSE_MOVE_MAPPINGS[index] for index in move_indices]\n",
    "    return [Move(from_square, to_square, promotion=promotion_type) for from_square, to_square, promotion_type in moves]\n",
    "\n",
    "\n",
    "def __precalculate_move_mappings() -> tuple[list[list[dict[PieceType | None, int]]], int]:\n",
    "    KNIGHT_MOVES = [(-2, -1), (-2, 1), (-1, -2), (-1, 2), (1, -2), (1, 2), (2, -1), (2, 1)]\n",
    "    ROOK_MOVES = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "    BISHOP_MOVES = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "\n",
    "    move_mappings: list[list[dict[PieceType | None, int]]] = [[{} for _ in range(64)] for _ in range(64)]\n",
    "    index = 0\n",
    "\n",
    "    def add_move(from_square: Square, to_square: Square, promotion_type: PieceType | None) -> None:\n",
    "        nonlocal index\n",
    "        move_mappings[from_square][to_square][promotion_type] = index\n",
    "        index += 1\n",
    "\n",
    "    def add_promotion_moves(from_square: Square, col: int, to_row: int) -> None:\n",
    "        for offset in (-1, 0, 1):\n",
    "            if 0 <= col + offset < 8:\n",
    "                to_square = square(col + offset, to_row)\n",
    "                add_move(from_square, to_square, QUEEN)\n",
    "                add_move(from_square, to_square, ROOK)\n",
    "                add_move(from_square, to_square, BISHOP)\n",
    "                add_move(from_square, to_square, KNIGHT)\n",
    "\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            from_square = square(col, row)\n",
    "\n",
    "            # Calculate knight moves from this square\n",
    "            for dx, dy in KNIGHT_MOVES:\n",
    "                if 0 <= row + dx < 8 and 0 <= col + dy < 8:  # Check if move is within bounds\n",
    "                    to_square = square(col + dy, row + dx)\n",
    "                    add_move(from_square, to_square, None)\n",
    "\n",
    "            # Calculate rook moves from this square\n",
    "            for dx, dy in ROOK_MOVES:\n",
    "                for i in range(1, 8):\n",
    "                    if 0 <= row + i * dx < 8 and 0 <= col + i * dy < 8:\n",
    "                        to_square = square(col + i * dy, row + i * dx)\n",
    "                        add_move(from_square, to_square, None)\n",
    "\n",
    "            # Calculate bishop moves from this square\n",
    "            for dx, dy in BISHOP_MOVES:\n",
    "                for i in range(1, 8):\n",
    "                    if 0 <= row + i * dx < 8 and 0 <= col + i * dy < 8:\n",
    "                        to_square = square(col + i * dy, row + i * dx)\n",
    "                        add_move(from_square, to_square, None)\n",
    "\n",
    "            # Calculate pawn promotion moves from this square\n",
    "            if row == 1:\n",
    "                add_promotion_moves(from_square, col, row - 1)\n",
    "            elif row == 6:\n",
    "                add_promotion_moves(from_square, col, row + 1)\n",
    "\n",
    "    return move_mappings, index\n",
    "\n",
    "\n",
    "def __precalculate_reverse_move_mappings(\n",
    "    move_mappings: list[list[dict[PieceType | None, int]]],\n",
    ") -> list[tuple[Square, Square, PieceType | None]]:\n",
    "    reverse_move_mappings: list[tuple[Square, Square, PieceType | None]] = [None] * ACTION_SIZE  # type: ignore\n",
    "\n",
    "    for from_square, moves in enumerate(move_mappings):\n",
    "        for to_square, promotional_mapping in enumerate(moves):\n",
    "            for promotion_type, index in promotional_mapping.items():\n",
    "                reverse_move_mappings[index] = (from_square, to_square, promotion_type)\n",
    "\n",
    "    return reverse_move_mappings\n",
    "\n",
    "\n",
    "__MOVE_MAPPINGS, ACTION_SIZE = __precalculate_move_mappings()\n",
    "__REVERSE_MOVE_MAPPINGS = __precalculate_reverse_move_mappings(__MOVE_MAPPINGS)\n",
    "\n",
    "\n",
    "def __encode_legal_moves(board: Board) -> NDArray[np.int8]:\n",
    "    \"\"\"\n",
    "    Encodes the legal moves of a chess board into a 1D numpy array.\n",
    "\n",
    "    Each entry in the array represents a possible move on the board. If the\n",
    "    corresponding move is legal, the entry is 1, and 0 otherwise. The array\n",
    "    has a length of TOTAL_MOVES, representing all possible moves from all squares\n",
    "    to all reachable squares.\n",
    "\n",
    "    :param board: The chess board to encode.\n",
    "    :return: A 1D numpy array representing the encoded legal moves.\n",
    "    \"\"\"\n",
    "    # Initialize a 1D array filled with zeros\n",
    "    # There are TOTAL_MOVES possible moves\n",
    "    legal_moves_encoded = np.zeros(ACTION_SIZE, dtype=np.int8)\n",
    "\n",
    "    # Iterate over all legal moves available in the position\n",
    "    for move in board.legal_moves:\n",
    "        legal_moves_encoded[encode_move(move)] = 1\n",
    "\n",
    "    return legal_moves_encoded\n",
    "\n",
    "\n",
    "def __filter_policy_with_legal_moves(policy: NDArray[np.float32], board: Board) -> NDArray[np.float32]:\n",
    "    \"\"\"\n",
    "    Filters a policy with the legal moves of a chess board.\n",
    "\n",
    "    The policy is a 1D numpy array representing the probabilities of each move\n",
    "    in the board. The legal moves are encoded in a 1D numpy array, where each\n",
    "    entry is 1 if the corresponding move is legal, and 0 otherwise. The policy\n",
    "    is then filtered to only include the probabilities of the legal moves.\n",
    "\n",
    "    :param policy: The policy to filter.\n",
    "    :param board: The chess board to filter the policy with.\n",
    "    :return: The filtered policy.\n",
    "    \"\"\"\n",
    "    legal_moves_encoded = __encode_legal_moves(board)\n",
    "    policy *= legal_moves_encoded\n",
    "    policy /= np.sum(policy)\n",
    "    return policy\n",
    "\n",
    "\n",
    "def __map_policy_to_moves(policy: NDArray[np.float32]) -> list[tuple[Move, float]]:\n",
    "    \"\"\"\n",
    "    Maps a filtered policy to a list of moves with their corresponding probabilities.\n",
    "\n",
    "    The policy is a 1D numpy array representing the probabilities of each move\n",
    "    in the board. The list of moves is a list of tuples, where each tuple contains\n",
    "    a move and its corresponding probability.\n",
    "\n",
    "    :param policy: The policy to map.\n",
    "    :return: The list of moves with their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    # Find indices where probability > 0\n",
    "    nonzero_indices = np.nonzero(policy > 0)[0]\n",
    "\n",
    "    # Decode all moves at once\n",
    "    moves = decode_moves(nonzero_indices)\n",
    "\n",
    "    # Pair up moves with their probabilities\n",
    "    moves_with_probabilities = list(zip(moves, policy[nonzero_indices]))\n",
    "\n",
    "    return moves_with_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "class AlphaMCTSNode:\n",
    "    @classmethod\n",
    "    def root(cls, board: Board) -> AlphaMCTSNode:\n",
    "        instance = cls(policy=1.0, move_to_get_here=Move.null(), parent=None, num_played_moves=0)\n",
    "        instance.board = board\n",
    "        instance.number_of_visits = 1.0\n",
    "        return instance\n",
    "\n",
    "    def __init__(\n",
    "        self, policy: float, move_to_get_here: Move, parent: AlphaMCTSNode | None, num_played_moves: int\n",
    "    ) -> None:\n",
    "        self.board: Board = None  # type: ignore\n",
    "        self.parent = parent\n",
    "        self.children: list[AlphaMCTSNode] = []\n",
    "        self.move_to_get_here = move_to_get_here\n",
    "        self.num_played_moves = num_played_moves  # This is the number of moves played to get to this node\n",
    "        self.number_of_visits = 0.0001  # Prevent division by zero\n",
    "        self.result_score = -1.0\n",
    "        self.policy = policy\n",
    "\n",
    "    def init(self) -> None:\n",
    "        \"\"\"Initializes the node by creating a board if it doesn't have one.\"\"\"\n",
    "        if not self.board:\n",
    "            if not self.parent or not self.parent.board:\n",
    "                raise ValueError('Parent node must have a board')\n",
    "\n",
    "            self.board = self.parent.board.copy(stack=False)\n",
    "            self.board.push(self.move_to_get_here)\n",
    "\n",
    "    @property\n",
    "    def is_terminal_node(self) -> bool:\n",
    "        return self.board is not None and self.board.is_game_over()\n",
    "\n",
    "    @property\n",
    "    def is_fully_expanded(self) -> bool:\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def expand(self, moves_with_scores: list[tuple[Move, float]]) -> None:\n",
    "        self.children = [\n",
    "            AlphaMCTSNode(score, move, parent=self, num_played_moves=self.num_played_moves + 1)\n",
    "            for move, score in moves_with_scores\n",
    "        ]\n",
    "\n",
    "        # Convert to NumPy arrays\n",
    "        self.children_number_of_visits = np.array([child.number_of_visits for child in self.children], dtype=np.float32)\n",
    "        self.children_result_scores = np.array([child.result_score for child in self.children], dtype=np.float32)\n",
    "        self.children_policies = np.array([child.policy for child in self.children], dtype=np.float32)\n",
    "\n",
    "    def back_propagate(self, result: float) -> None:\n",
    "        self.number_of_visits += 1.0\n",
    "        self.result_score += result\n",
    "        if self.parent:\n",
    "            child_index = self.parent.children.index(self)\n",
    "            self.parent.children_number_of_visits[child_index] += 1.0\n",
    "            self.parent.children_result_scores[child_index] += result\n",
    "            self.parent.back_propagate(result)\n",
    "\n",
    "    def best_child(self, c_param: float = 0.1) -> AlphaMCTSNode:\n",
    "        \"\"\"Selects the best child node using the UCB1 formula and initializes the best child before returning it.\"\"\"\n",
    "\n",
    "        q_score = 1 - ((self.children_result_scores / self.children_number_of_visits) + 1) / 2\n",
    "        policy_score = c_param * np.sqrt(self.number_of_visits) / (1 + self.children_number_of_visits)\n",
    "\n",
    "        ucb_scores = q_score + self.children_policies * policy_score\n",
    "\n",
    "        # Select the best child\n",
    "        best_child = self.children[np.argmax(ucb_scores)]\n",
    "        best_child.init()\n",
    "        return best_child\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"\"\"AlphaMCTSNode(\n",
    "{self.board}\n",
    "visits: {self.number_of_visits}\n",
    "depth: {self.num_played_moves}\n",
    "score: {self.result_score:.2f}\n",
    "policy: {self.policy:.2f}\n",
    "move: {self.move_to_get_here}\n",
    "children: {len(self.children)}\n",
    ")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AlphaZeroBot(ChessBot):\n",
    "    def __init__(self, network_model_file_path) -> None:\n",
    "        super().__init__('Alpha MCTS Bot')\n",
    "        self.model = Network()\n",
    "        self.model.load_state_dict(torch.load(network_model_file_path))\n",
    "\n",
    "    def think(self, board: Board) -> Move:\n",
    "        root = AlphaMCTSNode.root(board)\n",
    "\n",
    "        while not self.time_is_up:\n",
    "            self.iterate(root)\n",
    "\n",
    "        best_child = root.best_child(c_param=0.0)\n",
    "\n",
    "        print('---------------------- Alpha Zero Best Move ----------------------')\n",
    "        print(f'Best child has {best_child.number_of_visits:.4f} visits')\n",
    "        print(f'Best child has {best_child.result_score:.4f} result_score')\n",
    "        print(f'Best child has {best_child.policy:.4f} policy')\n",
    "        print('------------------------------------------------------------------')\n",
    "\n",
    "        return best_child.move_to_get_here\n",
    "\n",
    "    def iterate(self, root: AlphaMCTSNode) -> None:\n",
    "        current_node = root\n",
    "\n",
    "        while not current_node.is_terminal_node:\n",
    "            if current_node.is_fully_expanded:\n",
    "                current_node = current_node.best_child()\n",
    "            else:\n",
    "                moves_with_scores, result = self.evaluation(current_node.board)\n",
    "                current_node.expand(moves_with_scores)\n",
    "                current_node.back_propagate(result)\n",
    "                return\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluation(self, board: Board) -> tuple[list[tuple[Move, float]], float]:\n",
    "        policy, value = self.model.inference(encode_boards([board]).to(self.model.device))\n",
    "\n",
    "        moves = filter_policy_then_get_moves_and_probabilities(policy[0], board)\n",
    "\n",
    "        return moves, value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.engine\n",
    "\n",
    "class BaselineBot(ChessBot):\n",
    "    def __init__(self, engine_path: str, skill: int) -> None:\n",
    "        super().__init__(f'Baseline Bot ({engine_path})')\n",
    "        self.engine = chess.engine.SimpleEngine.popen_uci(engine_path)\n",
    "\n",
    "        # Set the skill level of the engine\n",
    "        # The skill level can be set from 0 to 20 (0 being the weakest and 20 the strongest)\n",
    "        self.engine.configure({'Skill Level': skill}) \n",
    "\n",
    "    def think(self, board: Board) -> Move:\n",
    "        result = self.engine.play(board, chess.engine.Limit(time=TIME_TO_THINK))\n",
    "        if result.move is None:\n",
    "            raise ValueError('The engine returned a None move')\n",
    "        return result.move\n",
    "    \n",
    "    def stop(self) -> None:\n",
    "        self.engine.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot prediction from Fen string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model file\n",
    "%mkdir -p models\n",
    "%cd models\n",
    "!wget https://github.com/official-stockfish/Stockfish/releases/download/sf_16/stockfish-ubuntu-x86-64-modern.tar\n",
    "%tar -xvf stockfish-ubuntu-x86-64-modern.tar\n",
    "%mv stockfish-ubuntu-x86-64-modern stockfish\n",
    "%rm stockfish-ubuntu-x86-64-modern.tar\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.engine\n",
    "\n",
    "network = Network()\n",
    "network.load_state_dict(torch.load(get_best_model_path()))\n",
    "\n",
    "stockfish = chess.engine.SimpleEngine.popen_uci('models/stockfish')\n",
    "\n",
    "mid_game_fens = [\n",
    "    \"r1bqkb1r/pp2pppp/2n2n2/2pp4/3PP3/2N2N2/PPP2PPP/R1BQKB1R w KQkq - 0 1\",\n",
    "    \"r1bq1rk1/ppp1bppp/2np1n2/3Np3/1PP1P3/2N5/PB3PPP/R2QKB1R b KQ - 0 1\",\n",
    "    \"r1bq1rk1/pppn1pbp/3p1np1/4p3/2PP4/2N2N2/PP2BPPP/R1BQ1RK1 w - - 0 1\",\n",
    "    \"r2q1rk1/ppp1bppp/2np1n2/1B2p3/1bP1P3/2N2N2/PP1QBPPP/R4RK1 w - - 0 1\",\n",
    "    \"2kr3r/ppp2ppp/2npb3/q7/3NP3/2N5/PPP1QPPP/R1B1K2R b KQ - 0 1\",\n",
    "    \"r1bq1rk1/1pp1npbp/p2p1np1/3Pp3/2P1P3/2N1BN2/PP2BPPP/R2Q1RK1 w - - 0 1\",\n",
    "    \"r2q1rk1/1bpp1ppp/p1n2n2/1p1pp3/3P1B2/2PBPN2/PP3PPP/R2QK2R w KQ - 0 1\",\n",
    "    \"r2q1rk1/ppp2ppp/2nbpn2/3p4/3P1B2/2NBPN2/PPP2PPP/R2QK2R b KQ - 0 1\",\n",
    "    \"rnbq1rk1/pp3pbp/3p1np1/2pPp3/2P1P3/2N2N2/PP3PPP/R1BQRBK1 b - - 0 1\",\n",
    "    \"r1bq1rk1/pp2ppbp/2np1np1/8/2PNP3/2N5/PP3PPP/R1BQKB1R w KQ - 0 1\"\n",
    "]\n",
    "\n",
    "network.eval()\n",
    "policy, value = network.inference(encode_boards([Board(fen) for fen in mid_game_fens]).to(network.device))\n",
    "\n",
    "for fen, (p, v) in zip(mid_game_fens, zip(policy, value)):\n",
    "    board = Board(fen)\n",
    "    moves_with_probabilities = filter_policy_then_get_moves_and_probabilities(p, board)\n",
    "    stockfish_result = stockfish.analyse(board, chess.engine.Limit(time=0.1))\n",
    "\n",
    "    print(f'FEN: {fen}')\n",
    "    print(f'Value: {v:.4f}')\n",
    "    print(f'Stockfish evaluation: {stockfish_result[\"score\"]}')\n",
    "    print(f'Moves with probabilities: {len(moves_with_probabilities)}')\n",
    "    \n",
    "    for move, probability in moves_with_probabilities:\n",
    "        print(f'{move}: {probability:.4f}')\n",
    "        \n",
    "        board.push(move)\n",
    "        stockfish_result = stockfish.analyse(board, chess.engine.Limit(time=0.1))\n",
    "        print(f'Stockfish evaluation of new Board state: {stockfish_result[\"score\"]}')\n",
    "        board.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot plays against itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot1 = AlphaZeroBot(get_best_model_path())\n",
    "bot2 = AlphaZeroBot(get_best_model_path())\n",
    "\n",
    "game_manager = GameManager(bot1, bot2)\n",
    "game_manager.play_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot vs Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = AlphaZeroBot(get_best_model_path())\n",
    "human = HumanPlayer()\n",
    "\n",
    "game_manager = GameManager(bot, human)\n",
    "game_manager.play_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot vs Baseline Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_vs_baseline(model_path: str, repetitions: int, skill: int) -> None:\n",
    "    bot = AlphaZeroBot(model_path)\n",
    "    baseline = BaselineBot('models/stockfish', skill=skill)\n",
    "\n",
    "    game_manager = GameManager(bot, baseline)\n",
    "    results = [game_manager.play_game() for _ in range(repetitions)]\n",
    "    \n",
    "    baseline.stop()\n",
    "    \n",
    "    wins, draws, losses = 0, 0, 0\n",
    "    \n",
    "    for j, result in enumerate(results):\n",
    "        print(f'Game {model_path}-{j}: {result.result}')\n",
    "        \n",
    "        if result.winner == WHITE:\n",
    "            wins += 1\n",
    "        elif result.winner == BLACK:\n",
    "            losses += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "            \n",
    "    print(f'Wins: {wins}, Draws: {draws}, Losses: {losses}')\n",
    "\n",
    "bot_vs_baseline(get_best_model_path(), repetitions=10, skill=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot vs Baseline for all last checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_best_model_path = get_best_model_path()\n",
    "best_model_iteration = int(current_best_model_path.split('_')[-1].replace('.pt', ''))\n",
    "\n",
    "for i in range(1, best_model_iteration + 1):\n",
    "    model_path = f'models/model_{i}.pt'\n",
    "    if not os.path.exists(model_path):\n",
    "        continue\n",
    "    \n",
    "    bot_vs_baseline(model_path, repetitions=10, skill=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
